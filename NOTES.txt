START FROM CHANGING THE JobMatcher ‚úÖ

NOW YOU TAKEN JOBMATCHER OPTION. YOU CREATED THE PYTHON ENV,
UPDATED THE SERVER,CLIENT,A ND ML_SERVICE
THERE IS AN ERROR IN POST METHOD IN API.JS IN CLIENT. START FROM THAT‚úÖ


API SERVICES FOR JOB LISTINGS(CHOICES):
| API / Service               | Free or Trial | Coverage                 | Notes                                                 |
| --------------------------- | ------------- | ------------------------ | ----------------------------------------------------- |
| **Rise ‚Äì Free Public Jobs** | Yes           | Limited (Rise-specific)  | CORS-enabled and free‚Äîto explore basic integration.   |
| **Jooble / Careerjet**      | Freemium      | Wide (aggregated boards) | Requires registration; possible usage limits.         |
| **TheirStack Job Postings** | Trial         | Very wide (16+ sources)  | Good for deep testing during trial period.            |
| **Coresignal Jobs API**     | Trial         | Large, refreshed dataset | Great for scalable integrations; subscription needed. |
| **Google CTS Job Search**   | Not directly  | Indexing ML search only  | You supply jobs; not suitable for fetching listings.  |

Model training for job matcher:
1. Problem restatement in your words

Input: A resume (free text).

Extracted features: Skills, job roles mentioned in the resume.

Output: A predicted job role (or set of possible roles) from a predefined list of real-world job roles stored in a database.

Essentially:
üëâ Resume text ‚Üí Extract structured features ‚Üí Match/ classify ‚Üí Retrieve standardized job role(s).

2. Core pipeline

This problem isn‚Äôt just Random Forest out-of-the-box. It needs a pipeline of NLP + ML + DB matching.

Step A: Data preparation

Collect a dataset of resumes (or synthetic resume-like entries). Each entry should have:

Text (skills, experiences, job titles).

Label = standardized job role (from your database).

Your database should contain a controlled list of job roles (e.g., ‚ÄúData Scientist‚Äù, ‚ÄúSoftware Engineer‚Äù, ‚ÄúProject Manager‚Äù, etc.).

Step B: Resume text preprocessing

Text cleaning: Lowercase, remove stopwords, punctuation.

Skill extraction: Use either

A predefined skills dictionary (e.g., NLP skills list: Python, SQL, Tableau, etc.), or

An NER model (Spacy, HuggingFace transformers trained on resumes).

Job role phrases: Extract titles like ‚ÄúSoftware Engineer‚Äù, ‚ÄúML Engineer‚Äù, etc. from past job experiences.

So after parsing, you get structured features like:

{
  "skills": ["python", "sql", "machine learning"],
  "mentioned_roles": ["data analyst", "intern"],
  "text": "full resume text..."
}

Step C: Feature representation

Convert extracted info into ML-friendly features:

Bag-of-Words / TF-IDF vectors on text.

Or use embeddings (e.g., sentence-BERT) for richer semantic meaning.

Optionally add binary features for skills (1 if present, 0 otherwise).

Step D: Model training (classification)

Now you can train a Random Forest Classifier:

Input: resume features (TF-IDF + skills indicators).

Target: standardized job role.

Random Forest is decent if your feature space is structured (skills, keywords).

If you only have text, Logistic Regression or Gradient Boosting / Transformer models often outperform RF on text classification.

Step E: Matching to database

After classification:

The predicted label is matched with your database of job roles.

If you want fuzzy matching (resume role text may not exactly match DB role), you can use:

Embedding similarity (cosine similarity between resume embedding & job role embedding).

Fuzzy string matching (e.g., Levenshtein distance).

3. Example workflow

Candidate uploads resume PDF.

Extract text ‚Üí parse skills & roles.

Vectorize ‚Üí pass into trained classifier.

Output predicted job role(s).

Query database: find best-matching standardized job title(s).

Return ranked list.

4. Implementation sketch (Python)

Here‚Äôs a simplified prototype with Random Forest:

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Example dataset: resumes + job role labels
df = pd.read_csv("resume_dataset.csv")  # columns: ["resume_text", "job_role"]

# Split
X_train, X_test, y_train, y_test = train_test_split(
    df["resume_text"], df["job_role"], test_size=0.2, stratify=df["job_role"], random_state=42
)

# Pipeline: TF-IDF + RandomForest
clf = Pipeline([
    ("tfidf", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),
    ("rf", RandomForestClassifier(n_estimators=300, class_weight="balanced", random_state=42))
])

clf.fit(X_train, y_train)

# Evaluation
pred = clf.predict(X_test)
print(classification_report(y_test, pred))

# Predict new resume
new_resume = """Experienced in Python, SQL, and ML. Worked as a Data Analyst for 2 years."""
print("Predicted role:", clf.predict([new_resume])[0])


Then once you have the predicted role, you‚Äôd:

Match it with database:

SELECT * FROM job_roles WHERE role_name = <predicted_role>;


(or use fuzzy/embedding search if not exact).

5. Extra considerations

Database integration: Use embeddings (e.g., sentence-BERT) to store job role embeddings. Query resumes against them for semantic match.

Multi-label cases: One resume may map to multiple roles ‚Üí use RandomForestClassifier in multi-label mode (or OneVsRestClassifier).

Explainability: Use feature importances or SHAP to show which skills led to the prediction.

Scalability: Random Forest is fine for ~100k samples, but for millions of resumes, gradient boosting (XGBoost/LightGBM) or Transformer embeddings are better



from flask import Flask, request, jsonify
from flask_cors import CORS
import os, tempfile
from pdfminer.high_level import extract_text as pdf_extract_text
import docx
import re
import spacy
from rapidfuzz import fuzz, process

nlp = spacy.load("en_core_web_sm")

app = Flask(__name__)
CORS(app)

# -------- Skill catalog (expand as you like) --------
SKILL_DB = {
    "programming": [
        "python","java","javascript","typescript","c++","c","golang","rust","php","ruby","matlab",
    ],
    "frontend": [
        "react","vite","next.js","redux","html","css","sass","tailwind","bootstrap","webpack",
    ],
    "backend": [
        "node.js","express","django","flask","spring","fastapi","graphql","rest","microservices",
    ],
    "data": [
        "sql","mysql","postgresql","mongodb","pandas","numpy","scikit-learn","tensorflow","pytorch","nlp","opencv",
    ],
    "devops": [
        "docker","kubernetes","aws","azure","gcp","ci/cd","jenkins","terraform","linux","nginx",
    ],
    "soft": [
        "communication","leadership","teamwork","problem solving","time management","agile","scrum",
    ],
}

# Flatten a normalized skill set
CANON_SKILLS = sorted({s.lower() for cat in SKILL_DB.values() for s in cat})

# -------- Helpers --------
def extract_text_from_file(path, filename):
    name = filename.lower()
    if name.endswith(".pdf"):
        return pdf_extract_text(path) or ""
    if name.endswith(".docx"):
        doc = docx.Document(path)
        return "\n".join(p.text for p in doc.paragraphs)
    # naive fallback (txt/doc)
    with open(path, "rb") as f:
        data = f.read()
    try:
        return data.decode("utf-8", errors="ignore")
    except Exception:
        return ""

SECTION_HEADS = [
    "education","experience","work experience","skills","projects",
    "personal information","contact","achievements","certifications","summary","objective"
]

def split_sections(text):
    lines = [l.strip() for l in text.splitlines()]
    buckets = {}
    current = "summary"
    buckets[current] = []

    def looks_like_heading(line):
        low = line.lower()
        if low in SECTION_HEADS: return True
        if re.match(r"^[A-Z][A-Z \-/&]{2,}$", line): return True  # ALLCAPS
        return False

    for ln in lines:
        if not ln: continue
        if looks_like_heading(ln):
            key = ln.lower()
            # map common variants
            if "work" in key and "experience" in key: key = "experience"
            if "personal" in key or "contact" in key: key = "personal information"
            if key not in buckets: buckets[key] = []
            current = key
        else:
            buckets.setdefault(current, []).append(ln)

    # join
    for k in list(buckets.keys()):
        buckets[k] = "\n".join(buckets[k]).strip()

    # normalize standard keys
    sections = {
        "summary": buckets.get("summary",""),
        "education": buckets.get("education",""),
        "experience": buckets.get("experience",""),
        "skills": buckets.get("skills",""),
        "projects": buckets.get("projects",""),
        "personal_info": buckets.get("personal information",""),
        "certifications": buckets.get("certifications",""),
    }
    return sections

def extract_personal_info(text):
    email = re.search(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", text)
    phone = re.search(r"(\+?\d[\d \-()]{7,}\d)", text)
    doc = nlp(text)
    name = None
    for ent in doc.ents:
        if ent.label_ == "PERSON":
            name = ent.text
            break
    return {
        "name": name,
        "email": email.group(0) if email else None,
        "phone": phone.group(0) if phone else None,
    }

def normalize_token(token):
    return token.lower().strip()

def extract_skills(text):
    text_low = text.lower()
    # seed from explicit Skills section
    skills_block = split_sections(text).get("skills","").lower()
    candidates = set()

    # dictionary match
    for skill in CANON_SKILLS:
        if re.search(rf"\b{re.escape(skill)}\b", text_low):
            candidates.add(skill)

    # add tokens from skills section (loose)
    for tok in re.findall(r"[a-zA-Z\+\.#]{2,}[\w\+\.#-]*", skills_block):
        tok = normalize_token(tok)
        if len(tok) < 2: continue
        # fuzzy match to known skills
        match, score, _ = process.extractOne(tok, CANON_SKILLS, scorer=fuzz.token_set_ratio)
        if score >= 90:
            candidates.add(match)

    # pack by categories
    categories = {cat: [] for cat in SKILL_DB.keys()}
    for cat, words in SKILL_DB.items():
        for w in words:
            if w.lower() in candidates:
                categories[cat].append(w.lower())

    flat = sorted(candidates)
    return {"by_category": categories, "all": flat}

# Simple rules: map skill clusters to job roles with required/core skills
ROLE_TEMPLATES = [
    {
        "title": "Frontend Developer",
        "must_have": ["javascript","react","html","css"],
        "nice_to_have": ["typescript","redux","vite","tailwind","webpack"]
    },
    {
        "title": "Backend Developer (Node.js)",
        "must_have": ["node.js","express","javascript"],
        "nice_to_have": ["mongodb","sql","rest","docker","aws"]
    },
    {
        "title": "Data Analyst",
        "must_have": ["python","pandas","numpy","sql"],
        "nice_to_have": ["scikit-learn","excel","tableau"]
    },
    {
        "title": "Machine Learning Engineer",
        "must_have": ["python","numpy","pandas","scikit-learn"],
        "nice_to_have": ["tensorflow","pytorch","nlp","docker","aws"]
    },
    {
        "title": "DevOps Engineer",
        "must_have": ["linux","docker","ci/cd"],
        "nice_to_have": ["kubernetes","aws","terraform","nginx"]
    },
]

def score_role(skills_all, must_have, nice_to_have):
    s = set(skills_all)
    if not set(must_have).issubset(s):
        return 0.0
    core = len(set(must_have))
    core_hit = len(set(must_have) & s)
    nice_hit = len(set(nice_to_have) & s)
    return min(1.0, 0.6 * (core_hit/core) + 0.4 * (nice_hit / max(1, len(nice_to_have))))

def suggest_roles(skills_all):
    scored = []
    for role in ROLE_TEMPLATES:
        score = score_role(skills_all, role["must_have"], role["nice_to_have"])
        if score > 0:
            scored.append({
                "title": role["title"],
                "score": round(score, 3),
                "description": f"Match based on skills: must {role['must_have']}, plus {role['nice_to_have']}"
            })
    # sort by score desc
    scored.sort(key=lambda x: x["score"], reverse=True)
    return scored[:8]

@app.route("/predict", methods=["POST"])
def predict():
    if "resume" not in request.files:
        return jsonify({"error": "No file part 'resume'"}), 400

    file = request.files["resume"]
    if file.filename == "":
        return jsonify({"error": "Empty filename"}), 400

    # save temp, extract, cleanup
    fd, path = tempfile.mkstemp()
    os.close(fd)
    try:
        file.save(path)
        text = extract_text_from_file(path, file.filename)
        sections = split_sections(text)

        # personal info (from entire text for higher recall)
        pinfo = extract_personal_info(text)

        # skills
        skills = extract_skills(text)
        roles = suggest_roles(skills["all"])

        # TODO (optional): integrate a legit job API provider here
        jobs = [
            {
                "title": r["title"],
                "score": r["score"],
                "description": r["description"],
                "source": "local-matcher",
            } for r in roles
        ]

        return jsonify({
            "extracted_text_preview": text[:1200],     # just a preview
            "sections": sections,                      # education/skills/experience/personal_info/...
            "personal_info": pinfo,
            "skills": skills,
            "matches": jobs
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    finally:
        try: os.remove(path)
        except Exception: pass

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)



// client/src/pages/JobMatcher.jsx

import { useState } from "react";
import { Button } from "@/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import {
  Upload,
  FileText,
  Brain,
  CheckCircle,
  Target,
  Zap,
  ArrowLeft,
  ArrowRight,
} from "lucide-react";
import Header from "@/components/Header";
import Footer from "@/components/Footer";
import { useToast } from "@/hooks/use-toast";
import { matchJob } from "@/services/api";

const JobMatcher = () => {
  const { toast } = useToast();
  const [uploadedFile, setUploadedFile] = useState(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [analysisComplete, setAnalysisComplete] = useState(false);
  const [jobMatches, setJobMatches] = useState([]);
  const [currentPage, setCurrentPage] = useState(1);
  const jobsPerPage = 100;

  // Handle file upload
  const handleFileUpload = (event) => {
    const file = event.target.files?.[0];
    if (file) {
      setUploadedFile(file);
      toast({
        title: "File uploaded successfully!",
        description: `${file.name} is ready for analysis.`,
      });
    }
  };

  // Analyze resume and fetch job matches
  const handleAnalyze = async () => {
    if (!uploadedFile) return;

    setIsAnalyzing(true);
    try {
      const formData = new FormData();
      formData.append("resume", uploadedFile);

      const { data } = await matchJob(formData);

      console.log("JobMatcher API response data:", data);

      // Normalize predictedRole to lowercase for jobs API
      if (data.predictedRole) {
        data.predictedRole = data.predictedRole.toLowerCase();
      }

      setJobMatches(data.matches || []);
      console.log("Job matches set in state:", data.matches || []);

      setAnalysisComplete(true);
      setCurrentPage(1);

    } catch (error) {
      toast({
        title: "Analysis Failed",
        description: "Could not analyze your resume. Please try again.",
        variant: "destructive",
      });
    } finally {
      setIsAnalyzing(false);
    }
  };

  // Pagination logic
  const indexOfLastJob = currentPage * jobsPerPage;
  const indexOfFirstJob = indexOfLastJob - jobsPerPage;
  const currentJobs = jobMatches.slice(indexOfFirstJob, indexOfLastJob);
  const totalPages = Math.ceil(jobMatches.length / jobsPerPage);

  return (
    <div className="min-h-screen">
      <Header />

      <div className="pt-20 pb-16">
        <div className="container mx-auto px-4">
          {/* Page Title */}
          <div className="text-center mb-12">
            <h1 className="text-4xl md:text-5xl font-bold mb-4">
              Job <span className="gradient-text">Matcher</span>
            </h1>
            <p className="text-xl text-muted-foreground max-w-2xl mx-auto">
              Upload your resume and find the best job matches for you.
            </p>
          </div>

          {/* Upload + Analysis */}
          {!analysisComplete ? (
            <div className="max-w-2xl mx-auto">
              {/* Upload Section */}
              <Card className="glass-card border-white/10 mb-8">
                <CardHeader className="text-center">
                  <div className="inline-flex items-center justify-center w-16 h-16 bg-gradient-primary rounded-2xl shadow-glow-primary mx-auto mb-4">
                    <Upload className="h-8 w-8 text-white" />
                  </div>
                  <CardTitle className="gradient-text">
                    Upload Your Resume
                  </CardTitle>
                  <CardDescription>
                    Supported formats: PDF, DOC, DOCX (Max 10MB)
                  </CardDescription>
                </CardHeader>
                <CardContent>
                  <div className="border-2 border-dashed border-white/20 rounded-lg p-8 text-center transition-colors hover:border-white/40">
                    <input
                      type="file"
                      id="resume-upload"
                      accept=".pdf,.doc,.docx"
                      onChange={handleFileUpload}
                      className="hidden"
                    />
                    <label
                      htmlFor="resume-upload"
                      className="cursor-pointer flex flex-col items-center space-y-4"
                    >
                      <FileText className="h-12 w-12 text-muted-foreground" />
                      <div>
                        <p className="text-lg font-medium">
                          Click to upload or drag and drop
                        </p>
                        <p className="text-sm text-muted-foreground">
                          Your resume will be analyzed securely and privately
                        </p>
                      </div>
                    </label>
                  </div>

                  {uploadedFile && (
                    <div className="mt-6 p-4 bg-white/5 rounded-lg border border-white/10">
                      <div className="flex items-center space-x-3">
                        <FileText className="h-6 w-6 text-primary" />
                        <div className="flex-1">
                          <p className="font-medium">{uploadedFile.name}</p>
                          <p className="text-sm text-muted-foreground">
                            {(uploadedFile.size / 1024 / 1024).toFixed(2)} MB
                          </p>
                        </div>
                        <CheckCircle className="h-6 w-6 text-green-400" />
                      </div>
                    </div>
                  )}
                </CardContent>
              </Card>

              {/* Analyze Button */}
              {uploadedFile && (
                <div className="text-center">
                  <Button
                    variant="neural"
                    size="lg"
                    onClick={handleAnalyze}
                    disabled={isAnalyzing}
                    className="shadow-glow-primary"
                  >
                    {isAnalyzing ? (
                      <>
                        <Brain className="h-5 w-5 mr-2 animate-spin" />
                        Finding Jobs...
                      </>
                    ) : (
                      <>
                        <Zap className="h-5 w-5 mr-2" />
                        Find Jobs
                      </>
                    )}
                  </Button>
                  {isAnalyzing && (
                    <p className="text-sm text-muted-foreground mt-4">
                      This may take a few moments while our AI analyzes your
                      resume...
                    </p>
                  )}
                </div>
              )}
            </div>
          ) : (
            /* Job Matches Result */
            <div className="space-y-8">
              <Card className="glass-card border-white/10">
                <CardHeader>
                  <CardTitle className="flex items-center space-x-2">
                    <Target className="h-6 w-6 text-primary" />
                    <span>Job Matches</span>
                  </CardTitle>
                </CardHeader>
                <CardContent className="space-y-4">
                  {currentJobs && currentJobs.length > 0 ? (
                    currentJobs.map((job, index) => (
                      <div
                        key={index}
                        className="p-4 rounded-lg bg-white/5 border border-white/10 shadow-md"
                      >
                        <h4 className="text-lg font-semibold">{job.title}</h4>
                        <p className="text-sm text-muted-foreground mb-2">
                          {job.hiring_organization_name} ‚Ä¢ {job.city}, {job.country}
                        </p>
                        <p className="text-sm text-muted-foreground mb-2">
                          Employment: {job.employment_type}
                        </p>
                        <p className="text-sm mb-3 line-clamp-4">{job.description}</p>
                        <p className="text-xs text-muted-foreground mb-4">
                          Source: {job.website}
                        </p>

                        <Button
                          variant="neural"
                          size="sm"
                          onClick={() => window.open(job.url, "_blank")}
                        >
                          View Job
                        </Button>
                      </div>
                    ))
                  ) : (
                    <p>No job matches found.</p>
                  )}

                  {/* Pagination Controls */}
                  {totalPages > 1 && (
                    <div className="flex justify-between items-center pt-6">
                      <Button
                        variant="outline"
                        size="sm"
                        disabled={currentPage === 1}
                        onClick={() => setCurrentPage((p) => p - 1)}
                      >
                        <ArrowLeft className="h-4 w-4 mr-2" /> Previous
                      </Button>
                      <p className="text-sm">
                        Page {currentPage} of {totalPages}
                      </p>
                      <Button
                        variant="outline"
                        size="sm"
                        disabled={currentPage === totalPages}
                        onClick={() => setCurrentPage((p) => p + 1)}
                      >
                        Next <ArrowRight className="h-4 w-4 ml-2" />
                      </Button>
                    </div>
                  )}
                </CardContent>
              </Card>
            </div>
          )}
        </div>
      </div>

      <Footer />
    </div>
  );
};

export default JobMatcher;
